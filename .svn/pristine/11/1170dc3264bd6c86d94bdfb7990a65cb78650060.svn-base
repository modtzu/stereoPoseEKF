/*
 * main.cpp
 *
 *  Created on: Sep 8, 2016
 *      Author: xwong
 *
 * 	estimate relative pose from stereo observation and create a global map
 *
 */

#include "input.h"
#include "imgFtRelated.h"
#include "pcVIsual.h"
#include "stereoSolver.h"
#include "ppTransEst.h"
#include "pclStereo.h"

#include "kltUncertainty.h"
#include "utility.h"

#include "featureManager.h"

ppTransEst ppTrans;
pcVIsual vi;
kltUncertainty KLTU;
utility UT;
pclStereo pclStr;

/// argument parser
void argumentParser(int argc, char** argv, std::string& fileExt, std::string& fileName,
		std::string& camCalibfile,std::string& optionFile, int& initCounter)
{

	for(int i =0; i < argc; i++)
	{
		if(strcmp("-e",argv[i])== 0)
		{
			fileExt = std::string(argv[i+1]);
		}
		else
		if(strcmp("-f",argv[i])== 0)
		{
			fileName = std::string(argv[i+1]);
		}
		else
		if(strcmp("-c",argv[i])== 0)
		{
			camCalibfile = std::string(argv[i+1]);
		}
		else
		if(strcmp("-o",argv[i])== 0)
		{
			optionFile = std::string(argv[i+1]);
		}
		else
		if(strcmp("-i",argv[i])== 0)
		{
			initCounter = atoi(argv[i+1]);
		}
	}
}


int main(int argc, char** argv)
{
	std::string fileExt, fileName, camCalibFile, optionFile;
	int initCounter = 0;

	/// parse argument
	argumentParser(argc, argv,fileExt,fileName, camCalibFile,optionFile,initCounter);

	/// setup image input reader
	input imgIn(fileExt,initCounter);

	/// Image at t = k-1
	cv::Mat imgR0,imgL0;

	/// get image at t = 0
	if(!imgIn.update(imgL0,imgR0))
	{
		std::cout<<"Error reading image input\n";
		return false;
	}

	/// feature manager
	featureManager ftMng(3,200);

	/// feature storage
	std::vector<cv::KeyPoint> vctFt0L, vctFt0R;
	std::vector<arma::mat> vctCovFt0L, vctCovFt0R;

	int numOfFt = ftMng.initFeaturePair(imgL0,imgR0);

	if(numOfFt>0)
		ftMng.getFeaturePair(&vctFt0L,&vctFt0R,&vctCovFt0L,&vctCovFt0R);
	else
		return false;

	/*
	 * Stereo camera setting
	 */
	double u0 = 305.408;
	double v0 = 244.826;
	double f = 808.083;
	double b = 0.240272;

	/*
	 * Compute full 3D map
	 */
	pcl::PointCloud<pcl::PointXYZRGB>::Ptr pointCloudPtr( new pcl::PointCloud<pcl::PointXYZRGB> );

	pclStr.solveStereo(imgL0,imgR0,pointCloudPtr,u0,v0,f,b);

	vi.addPt2Window("fullMap",pointCloudPtr,"0");


	/*
	 * keypoints 3D loc. in initial frame
	 */
	stereoSolver ste(u0,v0,f,b);
	std::vector<cv::Vec3f> vctPk,vctPkm1,vctPkm2;
	std::vector<arma::mat> vctCovPk,vctCovPkm1,vctCovPkm2;

	/// compute keypoint with covariance
	if(ste.computeDepthWtCov(&vctFt0L,&vctFt0R,vctPk,
								&vctCovFt0L,&vctCovFt0R,vctCovPk))
	{
		vctPkm1 = vctPk;
		vctPkm2 = vctPk;
	}
	else
		return false;

	/// compute keypoint without covariance
	if(ste.computeDepth(&vctFt0L,&vctFt0R,vctPk))
	{
		vctPkm1 = vctPk;
		vctPkm2 = vctPk;
	}
	else
	{
		return false;
	}

	/*
	 *  relative pose estimation
	 */

	/// Image at t = k
	cv::Mat imgRt,imgLt;

	arma::mat Rt0, Tt0;
	Rt0.eye(3,3);
	Tt0.zeros(3,1);
	int c = 0;
	int Fr = 0;

	std::vector<arma::mat> vctCamTransHist;
	std::vector<arma::mat> vctCamRotHist;

	/// loop through input images sequence
	while(true)
	{
		/// get next image
		if(!imgIn.update(imgLt,imgRt))
		{
			std::cout<<"End of image sequence\n";
			break;
		}

		Fr ++;

		///Track feature from L0 - Lt, R0 - Rt
		std::vector<cv::KeyPoint> vctFt1L, vctFt1R;
		std::vector<arma::mat> vctCovFt1L, vctCovFt1R;
		std::vector<int> rmvID;

		int numOfFt = ftMng.updateFeature(imgLt,imgRt,rmvID);

		if(numOfFt>0)
			ftMng.getFeaturePair(&vctFt1L,&vctFt1R,&vctCovFt1L,&vctCovFt1R);
		else
		{
			std::cout<<"No feature\n";
			 break;
		}

		if(!rmvID.empty())
		{
			int RC = rmvID.size();
			for(int i =0; i<rmvID.size(); i++)
			{
				int idToRemove = rmvID[RC - i - 1];

				vctPkm1.erase(vctPkm1.begin()+idToRemove);
				vctPkm2.erase(vctPkm2.begin()+idToRemove);
				vctPk.erase(vctPk.begin()+idToRemove);

			}
		}

		std::vector<cv::Vec3f> vctPkp1;

		/// compute 3D point from current stereo images + estimate relative pose to previous frame
		if(ste.computeDepth(&vctFt1L,&vctFt1R,vctPkp1))
		{
			char ptName[256];
			sprintf(ptName,"%d",Fr);

			arma::mat R, T;
			std::vector<int> ejectID;

			/// solve relative pose between P1 and P0
//			ppTrans.solve(vctP1,vctP,R,T); /// solve with non linear least square
//
//			/// solve with RANSAC remover
//			while(!ppTrans.solve(vctPk,vctPkp1,R,T,ejectID))
//			{
//				CS = ejectID.size();
//
//				for(int i= 0; i < CS; i++)
//				{
//					int k = CS - i - 1;
//					vctPk.erase(vctPk.begin()+k);
//					vctPkp1.erase(vctPkp1.begin()+k);
//					vctFt1R.erase(vctFt1R.begin()+k);
//					vctFt1L.erase(vctFt1L.begin()+k);
//				}
//				ejectID.clear();
//			}

			/// solve with linear formulation + 2nd / 3rd order system model
			if(c < 1)
			{
				ppTrans.solveLinear(vctPk,vctPkp1,R,T,ejectID);
			}
			else if(c < 2)
				ppTrans.solveLinear2ndOrder(vctPkm1,vctPk,vctPkp1,R,T,ejectID); /// solve with linear least square 2nd order model
			else
				ppTrans.solveLinear3rdOrder(vctPkm2,vctPkm1,vctPk,vctPkp1,R,T,ejectID); /// solve with linear least square 3rd order model

		 /// transform estimated relative pose back into initial frame
			T = -R.t()*T;
			R = R.t();

			Tt0 = Tt0 + Rt0*T;
			Rt0 = R*Rt0;

			vctCamTransHist.push_back(Tt0);
			vctCamRotHist.push_back(Rt0);

		/// print camera relative position to initial frame
			std::cout<<vctPk.size()<<","<<Tt0.t();

			/// visualize key points in initial frame.
			Eigen::Matrix4f transformMat = Eigen::Matrix4f::Identity();

			for(int i=0 ; i < 3; i ++)
			{
				for(int j=0 ; j < 3; j ++)
				{
					transformMat(i,j) = Rt0(i,j);
				}
				transformMat(i,3) = Tt0(i,0);
			}

			if(c == 3 || c > 20)
			{
				pcl::PointCloud<pcl::PointXYZRGB>::Ptr pointCloudPtr( new pcl::PointCloud<pcl::PointXYZRGB> );

				pclStr.solveStereo(imgL0,imgR0,pointCloudPtr,u0,v0,f,b);

				vi.addPt2Window("fullMap",pointCloudPtr,std::string(ptName),transformMat);

				if( c > 10)
					c = 4;
			}

		}
		else
		{
			std::cout<<"Error computing relative pose\n";
			break;
		}

		/// visualize tracked feature points in each image
		cv::Mat kf, kfR;
		cv::drawKeypoints(imgLt,vctFt1L,kf,cv::Scalar(0,255,255));
		cv::drawKeypoints(imgRt,vctFt1R,kfR,cv::Scalar(0,255,255));
		cv::imshow("kfR",kfR);
		cv::imshow("kf",kf);
		char k = cv::waitKey(10);

		if(k == 27)
			break;

		/// update image
		imgRt.copyTo(imgR0);
		imgLt.copyTo(imgL0);

		/// if number of feature is least than 10, add new feature (current strategy is reset feature)
		if(vctPk.size()< 20)
		{
			int numOfFt = ftMng.initFeaturePair(imgL0,imgR0);

			if(numOfFt>0)
				ftMng.getFeaturePair(&vctFt0L,&vctFt0R,&vctCovFt0L,&vctCovFt0R);
			else
			{
				std::cout<<"Error: no feature detected\n";
				break;
			}

			ste.computeDepth(&vctFt0L,&vctFt0R,vctPk);
			vctPkm2 = vctPk;
			vctPkm1 = vctPk;

			c = 0;

		}
		else
		{

			vctPkm2 = vctPkm1;
			vctPkm1 = vctPk;
			vctPk = vctPkp1;
			c++;
		}


	}

	vi.showWindow("fullMap");

	return 0;

	/// 3D points uncertainty
	/// relative pose uncertainty

	/// implement Kalman filter for subsequence state & covariance estimation

	/// Map / pose uncertainty

}
